{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ontological Engineering:\n",
    "NLP parsing and knowledge graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy download en_core_web_trf\n",
    "# sm, md, lg, trf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobia\\Documents\\nlp\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformer', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'merge_entities', 'merge_noun_chunks']\n",
      "[('This', 'PRON'), ('is', 'AUX'), ('a sentence', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "# import spacy\n",
    "# import spacy_transformers\n",
    "# # nlp = spacy.load(\"en_core_web_trf\", disable=[\"tagger\", \"attribute_ruler\", \"lemmatizer\", \"morphologizer\"])\n",
    "# nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# nlp.add_pipe(\"merge_entities\")     # merges named entities\n",
    "# nlp.add_pipe(\"merge_noun_chunks\")  # merges base noun-chunks\n",
    "\n",
    "# # import en_core_web_trf\n",
    "# # nlp = en_core_web_trf.load()\n",
    "# print(nlp.pipe_names)\n",
    "# doc = nlp(\"This is a sentence.\")\n",
    "# print([(w.text, w.pos_) for w in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Entities ===\n",
      "Anakin Skywalker      PERSON  [20:36]\n",
      "Darth Vader           PERSON  [44:55]\n",
      "Padmé Amidala         PERSON  [69:82]\n",
      "Luke                  PERSON  [84:88]\n",
      "Beru                  PERSON  [112:116]\n",
      "Owen                  PERSON  [127:131]\n",
      "R2-D2                 PRODUCT  [272:277]\n",
      "Leia                  PERSON  [302:306]\n",
      "Luke                  PERSON  [332:336]\n",
      "Obi-Wan “Ben” Kenobi  PERSON  [406:426]\n",
      "Yoda                  PERSON  [451:455]\n",
      "Dagobah               PRODUCT  [459:466]\n",
      "Luke                  PERSON  [468:472]\n",
      "Darth Vader           PERSON  [604:615]\n",
      "Cloud City            LOC  [623:633]\n",
      "\n",
      "=== Dependency Parse ===\n",
      "\n",
      "Sentence 1: Born to Jedi Knight Anakin Skywalker (later Darth Vader) and Senator Padmé Amidala, Luke was raised by his Aunt Beru and Uncle Owen on the desert planet Tatooine.\n",
      "  Born         → raised        (advcl)\n",
      "  to           → Born          (prep)\n",
      "  Jedi         → Knight        (compound)\n",
      "  Knight       → Skywalker     (compound)\n",
      "  Anakin       → Skywalker     (compound)\n",
      "  Skywalker    → to            (pobj)\n",
      "  (            → Skywalker     (punct)\n",
      "  later        → Vader         (advmod)\n",
      "  Darth        → Vader         (compound)\n",
      "  Vader        → Skywalker     (appos)\n",
      "  )            → Skywalker     (punct)\n",
      "  and          → Skywalker     (cc)\n",
      "  Senator      → Amidala       (compound)\n",
      "  Padmé        → Amidala       (compound)\n",
      "  Amidala      → Skywalker     (conj)\n",
      "  ,            → raised        (punct)\n",
      "  Luke         → raised        (nsubjpass)\n",
      "  was          → raised        (auxpass)\n",
      "  raised       → raised        (ROOT)\n",
      "  by           → raised        (agent)\n",
      "  his          → Beru          (poss)\n",
      "  Aunt         → Beru          (compound)\n",
      "  Beru         → by            (pobj)\n",
      "  and          → Beru          (cc)\n",
      "  Uncle        → Owen          (compound)\n",
      "  Owen         → Beru          (conj)\n",
      "  on           → raised        (prep)\n",
      "  the          → planet        (det)\n",
      "  desert       → planet        (compound)\n",
      "  planet       → on            (pobj)\n",
      "  Tatooine     → planet        (appos)\n",
      "  .            → raised        (punct)\n",
      "\n",
      "Sentence 2: Unaware of his true parentage, he worked as a moisture farmer until fate intervened: he encountered the droid R2-D2, which carried Princess Leia’s plea for help, setting Luke on a path that would forever change the galaxy.\n",
      "  Unaware      → worked        (advcl)\n",
      "  of           → Unaware       (prep)\n",
      "  his          → parentage     (poss)\n",
      "  true         → parentage     (amod)\n",
      "  parentage    → of            (pobj)\n",
      "  ,            → worked        (punct)\n",
      "  he           → worked        (nsubj)\n",
      "  worked       → encountered   (ccomp)\n",
      "  as           → worked        (prep)\n",
      "  a            → farmer        (det)\n",
      "  moisture     → farmer        (compound)\n",
      "  farmer       → as            (pobj)\n",
      "  until        → intervened    (mark)\n",
      "  fate         → intervened    (nsubj)\n",
      "  intervened   → worked        (advcl)\n",
      "  :            → encountered   (punct)\n",
      "  he           → encountered   (nsubj)\n",
      "  encountered  → encountered   (ROOT)\n",
      "  the          → droid         (det)\n",
      "  droid        → encountered   (dobj)\n",
      "  R2           → D2            (compound)\n",
      "  -            → D2            (punct)\n",
      "  D2           → droid         (appos)\n",
      "  ,            → droid         (punct)\n",
      "  which        → carried       (nsubj)\n",
      "  carried      → droid         (relcl)\n",
      "  Princess     → Leia          (compound)\n",
      "  Leia         → plea          (poss)\n",
      "  ’s           → Leia          (case)\n",
      "  plea         → carried       (dobj)\n",
      "  for          → plea          (prep)\n",
      "  help         → for           (pobj)\n",
      "  ,            → encountered   (punct)\n",
      "  setting      → encountered   (advcl)\n",
      "  Luke         → setting       (dobj)\n",
      "  on           → setting       (prep)\n",
      "  a            → path          (det)\n",
      "  path         → on            (pobj)\n",
      "  that         → change        (nsubj)\n",
      "  would        → change        (aux)\n",
      "  forever      → change        (advmod)\n",
      "  change       → path          (relcl)\n",
      "  the          → galaxy        (det)\n",
      "  galaxy       → change        (dobj)\n",
      "  .            → encountered   (punct)\n",
      "\n",
      "Sentence 3: Under the tutelage of Obi-Wan “Ben” Kenobi and, later, Jedi Master Yoda on Dagobah, Luke learned to harness the Force and hone his skills with a lightsaber.\n",
      "  Under        → learned       (prep)\n",
      "  the          → tutelage      (det)\n",
      "  tutelage     → Under         (pobj)\n",
      "  of           → tutelage      (prep)\n",
      "  Obi          → Kenobi        (nmod)\n",
      "  -            → Kenobi        (punct)\n",
      "  Wan          → Kenobi        (nmod)\n",
      "  “            → Kenobi        (punct)\n",
      "  Ben          → Kenobi        (nmod)\n",
      "  ”            → Kenobi        (punct)\n",
      "  Kenobi       → of            (pobj)\n",
      "  and          → Kenobi        (cc)\n",
      "  ,            → Kenobi        (punct)\n",
      "  later        → Kenobi        (advmod)\n",
      "  ,            → Kenobi        (punct)\n",
      "  Jedi         → Master        (compound)\n",
      "  Master       → Yoda          (compound)\n",
      "  Yoda         → Kenobi        (conj)\n",
      "  on           → Yoda          (prep)\n",
      "  Dagobah      → on            (pobj)\n",
      "  ,            → learned       (punct)\n",
      "  Luke         → learned       (nsubj)\n",
      "  learned      → learned       (ROOT)\n",
      "  to           → harness       (aux)\n",
      "  harness      → learned       (xcomp)\n",
      "  the          → Force         (det)\n",
      "  Force        → harness       (dobj)\n",
      "  and          → harness       (cc)\n",
      "  hone         → harness       (conj)\n",
      "  his          → skills        (poss)\n",
      "  skills       → hone          (dobj)\n",
      "  with         → hone          (prep)\n",
      "  a            → lightsaber    (det)\n",
      "  lightsaber   → with          (pobj)\n",
      "  .            → learned       (punct)\n",
      "\n",
      "Sentence 4: His rigorous training culminated in a fierce confrontation with Darth Vader aboard Cloud City, where he faced not only the dark side’s power but also the shattering revelation of his lineage\n",
      "  His          → training      (poss)\n",
      "  rigorous     → training      (amod)\n",
      "  training     → culminated    (nsubj)\n",
      "  culminated   → culminated    (ROOT)\n",
      "  in           → culminated    (prep)\n",
      "  a            → confrontation  (det)\n",
      "  fierce       → confrontation  (amod)\n",
      "  confrontation → in            (pobj)\n",
      "  with         → confrontation  (prep)\n",
      "  Darth        → Vader         (compound)\n",
      "  Vader        → with          (pobj)\n",
      "  aboard       → confrontation  (prep)\n",
      "  Cloud        → City          (compound)\n",
      "  City         → aboard        (pobj)\n",
      "  ,            → City          (punct)\n",
      "  where        → faced         (advmod)\n",
      "  he           → faced         (nsubj)\n",
      "  faced        → City          (relcl)\n",
      "  not          → power         (preconj)\n",
      "  only         → not           (advmod)\n",
      "  the          → side          (det)\n",
      "  dark         → side          (amod)\n",
      "  side         → power         (poss)\n",
      "  ’s           → side          (case)\n",
      "  power        → faced         (dobj)\n",
      "  but          → power         (cc)\n",
      "  also         → but           (advmod)\n",
      "  the          → revelation    (det)\n",
      "  shattering   → revelation    (amod)\n",
      "  revelation   → power         (conj)\n",
      "  of           → revelation    (prep)\n",
      "  his          → lineage       (poss)\n",
      "  lineage      → of            (pobj)\n",
      "[('Born', 'VERB'), ('to', 'ADP'), ('Jedi', 'PROPN'), ('Knight', 'PROPN'), ('Anakin', 'PROPN'), ('Skywalker', 'PROPN'), ('(', 'PUNCT'), ('later', 'ADV'), ('Darth', 'PROPN'), ('Vader', 'PROPN'), (')', 'PUNCT'), ('and', 'CCONJ'), ('Senator', 'PROPN'), ('Padmé', 'PROPN'), ('Amidala', 'PROPN'), (',', 'PUNCT'), ('Luke', 'PROPN'), ('was', 'AUX'), ('raised', 'VERB'), ('by', 'ADP'), ('his', 'PRON'), ('Aunt', 'PROPN'), ('Beru', 'PROPN'), ('and', 'CCONJ'), ('Uncle', 'PROPN'), ('Owen', 'PROPN'), ('on', 'ADP'), ('the', 'DET'), ('desert', 'NOUN'), ('planet', 'NOUN'), ('Tatooine', 'PROPN'), ('.', 'PUNCT'), ('Unaware', 'ADJ'), ('of', 'ADP'), ('his', 'PRON'), ('true', 'ADJ'), ('parentage', 'NOUN'), (',', 'PUNCT'), ('he', 'PRON'), ('worked', 'VERB'), ('as', 'ADP'), ('a', 'DET'), ('moisture', 'NOUN'), ('farmer', 'NOUN'), ('until', 'SCONJ'), ('fate', 'NOUN'), ('intervened', 'VERB'), (':', 'PUNCT'), ('he', 'PRON'), ('encountered', 'VERB'), ('the', 'DET'), ('droid', 'NOUN'), ('R2', 'PROPN'), ('-', 'PUNCT'), ('D2', 'PROPN'), (',', 'PUNCT'), ('which', 'PRON'), ('carried', 'VERB'), ('Princess', 'PROPN'), ('Leia', 'PROPN'), ('’s', 'PART'), ('plea', 'NOUN'), ('for', 'ADP'), ('help', 'NOUN'), (',', 'PUNCT'), ('setting', 'VERB'), ('Luke', 'PROPN'), ('on', 'ADP'), ('a', 'DET'), ('path', 'NOUN'), ('that', 'PRON'), ('would', 'AUX'), ('forever', 'ADV'), ('change', 'VERB'), ('the', 'DET'), ('galaxy', 'NOUN'), ('.', 'PUNCT'), ('Under', 'ADP'), ('the', 'DET'), ('tutelage', 'NOUN'), ('of', 'ADP'), ('Obi', 'PROPN'), ('-', 'PUNCT'), ('Wan', 'PROPN'), ('“', 'PUNCT'), ('Ben', 'PROPN'), ('”', 'PUNCT'), ('Kenobi', 'PROPN'), ('and', 'CCONJ'), (',', 'PUNCT'), ('later', 'ADV'), (',', 'PUNCT'), ('Jedi', 'PROPN'), ('Master', 'PROPN'), ('Yoda', 'PROPN'), ('on', 'ADP'), ('Dagobah', 'PROPN'), (',', 'PUNCT'), ('Luke', 'PROPN'), ('learned', 'VERB'), ('to', 'PART'), ('harness', 'VERB'), ('the', 'DET'), ('Force', 'PROPN'), ('and', 'CCONJ'), ('hone', 'VERB'), ('his', 'PRON'), ('skills', 'NOUN'), ('with', 'ADP'), ('a', 'DET'), ('lightsaber', 'NOUN'), ('.', 'PUNCT'), ('His', 'PRON'), ('rigorous', 'ADJ'), ('training', 'NOUN'), ('culminated', 'VERB'), ('in', 'ADP'), ('a', 'DET'), ('fierce', 'ADJ'), ('confrontation', 'NOUN'), ('with', 'ADP'), ('Darth', 'PROPN'), ('Vader', 'PROPN'), ('aboard', 'ADP'), ('Cloud', 'PROPN'), ('City', 'PROPN'), (',', 'PUNCT'), ('where', 'SCONJ'), ('he', 'PRON'), ('faced', 'VERB'), ('not', 'PART'), ('only', 'ADV'), ('the', 'DET'), ('dark', 'ADJ'), ('side', 'NOUN'), ('’s', 'PART'), ('power', 'NOUN'), ('but', 'CCONJ'), ('also', 'ADV'), ('the', 'DET'), ('shattering', 'VERB'), ('revelation', 'NOUN'), ('of', 'ADP'), ('his', 'PRON'), ('lineage', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# 1) Load model & text\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "#nlp.add_pipe(\"merge_entities\")     # merges named entities\n",
    "#nlp.add_pipe(\"merge_noun_chunks\")  # merges base noun-chunks\n",
    "#nlp.add_pipe(\"merge_subtokens\")  \n",
    "\n",
    "text = (\n",
    "        \"Like other tyrannosaurids, Tyrannosaurus was a bipedal carnivore with a massive skull balanced by a long, heavy tail. \"\n",
    "        \"Relative to its large and powerful hind limbs, the forelimbs of Tyrannosaurus were short but unusually powerful for their size, and they had two clawed digits. \"\n",
    "        \"The most complete specimen measures 12.3–12.4 m (40–41 ft) in length, but according to most modern estimates, Tyrannosaurus could have exceeded sizes of 13 m (43 ft) in length, 3.7–4 m (12–13 ft) in hip height, and 8.8 t (8.7 long tons; 9.7 short tons) in mass.\"\n",
    "        \"Although some other theropods might have rivaled or exceeded Tyrannosaurus in size, it is still among the largest known land predators, with its estimated bite force being the largest among all terrestrial animals. \"\n",
    "        \"By far the largest carnivore in its environment, Tyrannosaurus rex was most likely an apex predator, preying upon hadrosaurs, juvenile armored herbivores like ceratopsians and ankylosaurs, and possibly sauropods. Some experts have suggested the dinosaur was primarily a scavenger. \"\n",
    "        \"The question of whether Tyrannosaurus was an apex predator or a pure scavenger was among the longest debates in paleontology. \" \n",
    "        \"Most paleontologists today accept that Tyrannosaurus was both a predator and a scavenger.\" \n",
    "    )\n",
    "\n",
    "text2 = (\"Born to Jedi Knight Anakin Skywalker (later Darth Vader) and Senator Padmé Amidala, Luke was raised by his Aunt Beru and Uncle Owen on the desert planet Tatooine.\" \n",
    "         \"Unaware of his true parentage, he worked as a moisture farmer until fate intervened: he encountered the droid R2-D2, which carried Princess Leia’s plea for help, setting Luke on a path that would forever change the galaxy.\"\n",
    "         \"Under the tutelage of Obi-Wan “Ben” Kenobi and, later, Jedi Master Yoda on Dagobah, Luke learned to harness the Force and hone his skills with a lightsaber.\" \n",
    "         \"His rigorous training culminated in a fierce confrontation with Darth Vader aboard Cloud City, where he faced not only the dark side’s power but also the shattering revelation of his lineage \")\n",
    "\n",
    "text3 = (\"Archaeopteryx (from the Greek archaîos “ancient” + ptéryx “wing”; German Urvogel, “primeval bird”) is a genus of bird-like dinosaurs that lived in the Late Jurassic (~150 Mya) in what is now southern Germany. Roughly magpie-sized (up to 0.5 m long), it combined avian features (broad, flight-capable wings and advanced feather impressions) with classic theropod traits (sharp-toothed jaws, three-fingered claws, long bony tail, and a hyperextensible second toe). Because it bridges non-avian dinosaurs and modern birds, Archaeopteryx is celebrated as one of the most important transitional fossils in vertebrate evolution. First known from a single feather described in 1861, twelve more body-fossil specimens have since surfaced—almost all from the Solnhofen limestone quarries. The “London” specimen (1861) and the more complete “Berlin” specimen (1874–75) remain the best-preserved examples. These fossils not only bolstered early acceptance of Darwin’s theory of evolution but also established that feathers arose before true birds, reshaping our understanding of dinosaur–bird relationships.\")\n",
    "\n",
    "text4 = (\"Quetzalcoatlus northropi is one of the largest known pterosaurs—and indeed one of the largest flying animals ever to have lived. Named for the feathered serpent god Quetzalcoatl of Aztec mythology and paleontologist John Northrop, it soared the skies of what is now western North America during the Late Cretaceous, roughly 70–66 million years ago. With an estimated wingspan of 10–11 meters (33–36 feet), Quetzalcoatlus combined ultra-light, hollow bones and an aerodynamic skull crest to remain airborne. Its long, slender beak lacked teeth, suggesting a feeding strategy focused on small vertebrates or carrion rather than fish snatching; its robust hind limbs imply a terrestrial stalking style, picking prey on shorelines or inland plains before taking flight in powerful strokes of its membranous wings. Fossils of Quetzalcoatlus were first uncovered in the 1970s within the Maastrichtian deposits of Big Bend National Park, Texas. Unlike the marine pterosaurs found closer to ancient shorelines, these specimens came from inland floodplain sediments—evidence that some giant pterosaurs thrived far from the coasts. As both apex aerial predators and efficient scavengers, Quetzalcoatlus and its kin help paint a richer picture of Late Cretaceous ecosystems, where the mastery of flight unlocked entirely new niches among Mesozoic reptiles.\")\n",
    "\n",
    "doc = nlp(text2) \n",
    "\n",
    "# 2) Print named entities\n",
    "print(\"=== Entities ===\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:20}  {ent.label_}  [{ent.start_char}:{ent.end_char}]\")\n",
    "\n",
    "# 3) Print dependency arcs sentence by sentence\n",
    "print(\"\\n=== Dependency Parse ===\")\n",
    "for i, sent in enumerate(doc.sents, 1):\n",
    "    print(f\"\\nSentence {i}: {sent.text}\")\n",
    "    for token in sent:\n",
    "        # token.dep_: dependency label; token.head: the \"governor\"\n",
    "        print(f\"  {token.text:12} → {token.head.text:12}  ({token.dep_})\")\n",
    "        \n",
    "print([(w.text, w.pos_) for w in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Skywalker, Luke, Beru, planet, parentage, farmer, fate, help, path, tutelage, Kenobi, Dagobah, Luke, lightsaber, training, confrontation, Vader, City, lineage]\n",
      "Main topic: Luke\n",
      "Label: PERSON\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import spacy\n",
    "from spacy.tokens import Span, Token\n",
    "\n",
    "from typing import Any, Iterable, Optional\n",
    "\n",
    "def most_common_by_text(seq):\n",
    "    \"\"\"\n",
    "    Return the object in `seq` whose `.text` value appears most frequently.\n",
    "    If `seq` is empty, returns None.\n",
    "    If multiple objects share the top frequency, returns the first one seen.\n",
    "    \"\"\"\n",
    "    # build counts of each text\n",
    "    counts = {}\n",
    "    for obj in seq:\n",
    "        text = getattr(obj, \"text\", obj)  # use obj itself if no .text\n",
    "        counts[text] = counts.get(text, 0) + 1\n",
    "\n",
    "    if not counts:\n",
    "        return None\n",
    "\n",
    "    # find the text with the highest count\n",
    "    max_text = None\n",
    "    max_count = 0\n",
    "    for text, cnt in counts.items():\n",
    "        if cnt > max_count:\n",
    "            max_text, max_count = text, cnt\n",
    "\n",
    "    # return the first object whose text matches\n",
    "    for obj in seq:\n",
    "        if getattr(obj, \"text\", obj) == max_text:\n",
    "            return obj\n",
    "    return None\n",
    "        \n",
    "\n",
    "def extract_topic(doc):\n",
    "    \"\"\"Extract the main topic of the document and its label.\"\"\"\n",
    "    # collect candidates as either Spans (entities) or Tokens (nsubj NOUN/PROPN)\n",
    "    valid_dep = [\"nsubj\", \"pobj\", \"nsubjpass\", \"puncr\", \"prep\"]  # valid dependency labels for subjects\n",
    "    candidates = []\n",
    "    ent_candidates = []\n",
    "    # first all named‐entity spans\n",
    "    for ent in doc.ents:\n",
    "        ent_candidates.append(ent)\n",
    "    # then any noun/proper‐noun subjects\n",
    "    for token in doc:\n",
    "        if token.dep_ in valid_dep and token.pos_ in (\"NOUN\", \"PROPN\"):\n",
    "            candidates.append(token)\n",
    "\n",
    "    if not candidates:\n",
    "        return None, None\n",
    "    \n",
    "    print(candidates)\n",
    "\n",
    "    # pick the most frequent\n",
    "    topic_obj = most_common_by_text(candidates)\n",
    "\n",
    "    # if it's a Span, use its label_\n",
    "    if isinstance(topic_obj, Span):\n",
    "        return topic_obj.text, topic_obj.label_\n",
    "\n",
    "    # if it's a Token inside an entity, use token.ent_type_\n",
    "    if isinstance(topic_obj, Token) and topic_obj.ent_type_:\n",
    "        return topic_obj.text, topic_obj.ent_type_\n",
    "\n",
    "    # check if this token text is a named entity\n",
    "    for ent in ent_candidates:\n",
    "        if topic_obj.text == ent.text:\n",
    "            return topic_obj.text, ent.label_\n",
    "    # otherwise fall back to the UPOS tag\n",
    "    return topic_obj.text, \"NaT\" # \"NaT\" = Not a Topic\n",
    "\n",
    "\n",
    "topic, label = extract_topic(doc)\n",
    "print(\"Main topic:\", topic)\n",
    "print(\"Label:\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_subtree(tok):\n",
    "    return \" \".join(t.text for t in tok.subtree)\n",
    "\n",
    "\n",
    "# Language extraction rules\n",
    "\n",
    "def extract_appositions(sent) -> list[tuple[str,str,str]]:\n",
    "    # Rule 1: appos (“X, a Y, …”)\n",
    "    triples = []\n",
    "    for tok in sent:\n",
    "        if tok.dep_ == \"appos\" and tok.head.dep_ in (\"nsubj\",\"dobj\",\"pobj\",\"attr\"):\n",
    "            subj = sent_subtree(tok.head)\n",
    "            obj  = sent_subtree(tok)\n",
    "            triples.append((subj, \"is a\", obj))\n",
    "    return triples\n",
    "\n",
    "# -Rule 2: Conjunctive splits\n",
    "def extract_conjunctions(sent):\n",
    "    \"\"\"\n",
    "    Splits conjunctive subjects and objects:\n",
    "    E.g. \"A and B were C\" => (\"A\", \"were\", \"C\") and (\"B\", \"were\", \"C\")\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "    roots = [t for t in sent if t.dep_ == \"ROOT\"]\n",
    "    if not roots:\n",
    "        return triples\n",
    "    root = roots[0]\n",
    "    # Gather subjects and objects\n",
    "    subs = [c for c in root.lefts if \"subj\" in c.dep_]\n",
    "    objs = [c for c in root.rights if c.dep_ in (\"dobj\",\"pobj\",\"iobj\",\"attr\",\"acomp\")]\n",
    "    if not subs or not objs:\n",
    "        return triples\n",
    "    # Expand conjuncts\n",
    "    sub_list = [subs[0]] + list(subs[0].conjuncts)\n",
    "    obj_list = [objs[0]] + list(objs[0].conjuncts)\n",
    "    # Build relation text\n",
    "    aux = [c.text for c in root.lefts if c.dep_ in (\"aux\",\"auxpass\",\"neg\",\"prt\")]\n",
    "    rel = \" \".join(aux + [root.text])\n",
    "    # Create one triple per combination\n",
    "    for s in sub_list:\n",
    "        for o in obj_list:\n",
    "            triples.append((sent_subtree(s), rel, sent_subtree(o)))\n",
    "    return triples\n",
    "\n",
    "# -Rule 3: Prepositional attachments\n",
    "def extract_prepositions(sent):\n",
    "    \"\"\"\n",
    "    Extracts prepositional relations:\n",
    "    E.g. \"X with Y\" => (\"X\", \"with\", \"Y\")\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "    roots = [t for t in sent if t.dep_ == \"ROOT\"]\n",
    "    if not roots:\n",
    "        return triples\n",
    "    root = roots[0]\n",
    "    # For each prep child of the root\n",
    "    for prep in [c for c in root.children if c.dep_ == \"prep\"]:\n",
    "        pobj = next((c for c in prep.children if c.dep_ == \"pobj\"), None)\n",
    "        if pobj:\n",
    "            triples.append((sent_subtree(root), prep.text, sent_subtree(pobj)))\n",
    "    return triples\n",
    "\n",
    "\n",
    "def extract_numeric_measures(sent) -> list[tuple[str,str,str]]:\n",
    "    # Rule 4: numbers + units\n",
    "    triples = []\n",
    "    for num in [t for t in sent if t.like_num]:\n",
    "        # look for a nearby unit or prep+unit\n",
    "        unit = next((c for c in num.rights if c.dep_ in (\"nummod\",\"npadvmod\")), None)\n",
    "        if not unit:\n",
    "            # maybe its attached via prep: \"in length\"\n",
    "            prep = next((c for c in sent if c.dep_==\"prep\" and any(n.like_num for n in c.rights)), None)\n",
    "            if prep:\n",
    "                unit = prep\n",
    "        if unit:\n",
    "            subj = sent_subtree(num.head if num.head.pos_==\"NOUN\" else roots[0])\n",
    "            measure = \" \".join(t.text for t in unit.subtree)\n",
    "            triples.append((subj, \"has_measure\", f\"{num.text} {measure}\"))\n",
    "    return triples\n",
    "\n",
    "# -Rule 5: Adjectival modifiers\n",
    "def extract_adjectival_modifiers(sent):\n",
    "    \"\"\"\n",
    "    Extracts noun-adjective pairs as \"is\" relations:\n",
    "    E.g. \"powerful jaws\" => (\"jaws\", \"is\", \"powerful\")\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "    for noun in [t for t in sent if t.pos_ == \"NOUN\"]:\n",
    "        for adj in [c for c in noun.lefts if c.dep_ == \"amod\"]:\n",
    "            triples.append((sent_subtree(noun), \"is\", adj.text))\n",
    "    return triples\n",
    "\n",
    "# -Rule 6: Clausal complements (ccomp/xcomp)\n",
    "def extract_clausal_complements(sent):\n",
    "    \"\"\"\n",
    "    Extracts clausal complements:\n",
    "    E.g. \"They said that X is Y\" => (\"X\", \"is\", \"Y\")\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "    for tok in sent:\n",
    "        if tok.dep_ in (\"ccomp\", \"xcomp\"):\n",
    "            subj = next((c for c in tok.lefts if \"subj\" in c.dep_), None)\n",
    "            obj  = next((c for c in tok.children if c.dep_ in (\"dobj\",\"pobj\",\"attr\",\"acomp\")), None)\n",
    "            if subj:\n",
    "                subj_text = sent_subtree(subj)\n",
    "                rel = tok.text\n",
    "                obj_text = sent_subtree(obj) if obj else \"\"\n",
    "                triples.append((subj_text, rel, obj_text))\n",
    "    return triples\n",
    "\n",
    "def extract_acl_relcl(sent) -> list[tuple[str,str,str]]:\n",
    "    # Rule 7: adjectival & relative clauses\n",
    "    triples = []\n",
    "    for tok in sent:\n",
    "        if tok.dep_ in (\"acl\",\"relcl\"):\n",
    "            subj = sent_subtree(tok.head)\n",
    "            rel  = tok.text\n",
    "            # find the object or its complement (dobj/attr/etc)\n",
    "            obj = next((c for c in tok.children if c.dep_ in (\"dobj\",\"pobj\",\"attr\",\"acomp\")), None)\n",
    "            if obj:\n",
    "                triples.append((subj, rel, sent_subtree(obj)))\n",
    "    return triples\n",
    "\n",
    "# -Rule 8: Possessives & genitives\n",
    "def extract_possessives(sent):\n",
    "    \"\"\"\n",
    "    Extracts possessive relations:\n",
    "    E.g. \"Tyrannosaurus's tail\" => (\"Tyrannosaurus\", \"has\", \"tail\")\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "    for tok in sent:\n",
    "        if tok.dep_ == \"poss\":\n",
    "            owner = sent_subtree(tok)\n",
    "            owned = sent_subtree(tok.head)\n",
    "            triples.append((owner, \"has\", owned))\n",
    "    return triples\n",
    "\n",
    "def extract_passive(sent) -> list[tuple[str,str,str]]:\n",
    "    # Rule 9: passive “X was discovered by Y”\n",
    "    triples = []\n",
    "    roots = [t for t in sent if t.dep_==\"ROOT\"]\n",
    "    if not roots:\n",
    "        return triples\n",
    "    root = roots[0]\n",
    "    if any(c.dep_==\"nsubjpass\" for c in root.children):\n",
    "        subj = sent_subtree(next(c for c in root.children if c.dep_==\"nsubjpass\"))\n",
    "        agent = next((c for c in root.children if c.dep_==\"agent\"), None)\n",
    "        if agent:\n",
    "            # agent subtree gives “by Y”\n",
    "            obj = sent_subtree(next(c for c in agent.children if c.dep_==\"pobj\"))\n",
    "            triples.append((obj, f\"{root.text} (passive)\", subj))\n",
    "    return triples\n",
    "\n",
    "def extract_neg_modality(sent) -> list[tuple[str,str,str]]:\n",
    "    # Rule 10: attach negation & auxiliaries onto relations\n",
    "    # This can either annotate existing triples or emit disclaimers\n",
    "    # For simplicity, we’ll prepend “not” / “could have” when found:\n",
    "    roots = [t for t in sent if t.dep_==\"ROOT\"]\n",
    "    if not roots:\n",
    "        return []\n",
    "    root = roots[0]\n",
    "    aux = [tok.text for tok in root.lefts if tok.dep_ in (\"aux\",\"auxpass\",\"neg\")]\n",
    "    if aux:\n",
    "        # find a simple nsubj + dobj for demonstration\n",
    "        subj = next((c for c in root.lefts if \"subj\" in c.dep_), None)\n",
    "        obj  = next((c for c in root.rights if c.dep_ in (\"dobj\",\"pobj\",\"attr\",\"acomp\")), None)\n",
    "        if subj and obj:\n",
    "            rel = \" \".join(aux + [root.text])\n",
    "            return [(sent_subtree(subj), rel, sent_subtree(obj))]\n",
    "    return []\n",
    "\n",
    "# -Rule 11: Named-entity facts\n",
    "def extract_ner_facts(doc):\n",
    "    \"\"\"\n",
    "    Emits simple facts for named entities:\n",
    "    E.g. (\"Tyrannosaurus rex\", \"is_entity\", \"PERSON\")\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "    for ent in doc.ents:\n",
    "        triples.append((ent.text, \"is_entity\", ent.label_))\n",
    "    return triples\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple 2: ('he', 'encountered', 'the droid R2 - D2 , which carried Princess Leia ’s plea for help')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# subject-predicate-object\n",
    "def extract_spo(sent):\n",
    "    # 1) Find the main verb\n",
    "    roots = [t for t in sent if t.dep_ == \"ROOT\"]\n",
    "    if not roots:\n",
    "        return None\n",
    "    root = roots[0]\n",
    "\n",
    "    # 2) Subject(s): any child with “subj” in its dep_\n",
    "    subs = [child for child in root.lefts if \"subj\" in child.dep_]\n",
    "    # 3) Object(s): expand to attr, acomp, dobj, pobj, iobj\n",
    "    objs = [\n",
    "        child\n",
    "        for child in root.rights\n",
    "        if child.dep_ in (\"dobj\", \"pobj\", \"iobj\", \"attr\", \"acomp\")\n",
    "    ]\n",
    "\n",
    "    if not subs or not objs:\n",
    "        return None\n",
    "\n",
    "    # 4) Build full phrases\n",
    "    subj_phrase = sent_subtree(subs[0])\n",
    "    obj_phrase  = sent_subtree(objs[0])\n",
    "\n",
    "    # 5) Build the relation: include auxiliaries, negations, particles\n",
    "    aux = [tok.text for tok in root.lefts if tok.dep_ in (\"aux\", \"auxpass\", \"neg\", \"prt\")]\n",
    "    rel = \" \".join(aux + [root.text])\n",
    "\n",
    "    return (subj_phrase, rel, obj_phrase)\n",
    "\n",
    "\n",
    "for i, sent in enumerate(doc.sents, 1):\n",
    "    spo = extract_spo(sent)\n",
    "    if spo:\n",
    "        print(f\"Triple {i}:\", spo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple 1: ('Jedi Knight Anakin Skywalker ( later Darth Vader ) and Senator Padmé Amidala', 'is a', 'later Darth Vader')\n",
      "Triple 2: ('the desert planet Tatooine', 'is a', 'Tatooine')\n",
      "Triple 3: ('Born to Jedi Knight Anakin Skywalker ( later Darth Vader ) and Senator Padmé Amidala , Luke was raised by his Aunt Beru and Uncle Owen on the desert planet Tatooine .', 'on', 'the desert planet Tatooine')\n",
      "Triple 4: ('his', 'has', 'his Aunt Beru and Uncle Owen')\n",
      "Triple 5: ('his Aunt Beru and Uncle Owen', 'raised (passive)', 'Luke')\n",
      "Triple 6: ('Anakin Skywalker', 'is_entity', 'PERSON')\n",
      "Triple 7: ('Darth Vader', 'is_entity', 'PERSON')\n",
      "Triple 8: ('Padmé Amidala', 'is_entity', 'PERSON')\n",
      "Triple 9: ('Luke', 'is_entity', 'PERSON')\n",
      "Triple 10: ('Beru', 'is_entity', 'PERSON')\n",
      "Triple 11: ('Owen', 'is_entity', 'PERSON')\n",
      "Triple 12: ('R2-D2', 'is_entity', 'PRODUCT')\n",
      "Triple 13: ('Leia', 'is_entity', 'PERSON')\n",
      "Triple 14: ('Obi-Wan “Ben” Kenobi', 'is_entity', 'PERSON')\n",
      "Triple 15: ('Yoda', 'is_entity', 'PERSON')\n",
      "Triple 16: ('Dagobah', 'is_entity', 'PRODUCT')\n",
      "Triple 17: ('Cloud City', 'is_entity', 'LOC')\n",
      "Triple 18: ('he', 'encountered', 'the droid R2 - D2 , which carried Princess Leia ’s plea for help')\n",
      "Triple 19: ('the droid R2 - D2 , which carried Princess Leia ’s plea for help', 'is a', 'R2 - D2')\n",
      "Triple 20: ('his true parentage', 'is', 'true')\n",
      "Triple 21: ('he', 'worked', '')\n",
      "Triple 22: ('the droid R2 - D2 , which carried Princess Leia ’s plea for help', 'carried', 'Princess Leia ’s plea for help')\n",
      "Triple 23: ('a path that would forever change the galaxy', 'change', 'the galaxy')\n",
      "Triple 24: ('his', 'has', 'his true parentage')\n",
      "Triple 25: ('Princess Leia ’s', 'has', 'Princess Leia ’s plea for help')\n",
      "Triple 26: ('Under the tutelage of Obi - Wan “ Ben ” Kenobi and , later , Jedi Master Yoda on Dagobah , Luke learned to harness the Force and hone his skills with a lightsaber .', 'Under', 'the tutelage of Obi - Wan “ Ben ” Kenobi and , later , Jedi Master Yoda on Dagobah')\n",
      "Triple 27: ('his', 'has', 'his skills')\n",
      "Triple 28: ('His rigorous training culminated in a fierce confrontation with Darth Vader aboard Cloud City , where he faced not only the dark side ’s power but also the shattering revelation of his lineage', 'in', 'a fierce confrontation with Darth Vader aboard Cloud City , where he faced not only the dark side ’s power but also the shattering revelation of his lineage')\n",
      "Triple 29: ('His rigorous training', 'is', 'rigorous')\n",
      "Triple 30: ('a fierce confrontation with Darth Vader aboard Cloud City , where he faced not only the dark side ’s power but also the shattering revelation of his lineage', 'is', 'fierce')\n",
      "Triple 31: ('the dark side ’s', 'is', 'dark')\n",
      "Triple 32: ('the shattering revelation of his lineage', 'is', 'shattering')\n",
      "Triple 33: ('Cloud City , where he faced not only the dark side ’s power but also the shattering revelation of his lineage', 'faced', 'not only the dark side ’s power but also the shattering revelation of his lineage')\n",
      "Triple 34: ('His', 'has', 'His rigorous training')\n",
      "Triple 35: ('the dark side ’s', 'has', 'not only the dark side ’s power but also the shattering revelation of his lineage')\n",
      "Triple 36: ('his', 'has', 'his lineage')\n"
     ]
    }
   ],
   "source": [
    "all_triples = []\n",
    "for sent in doc.sents:\n",
    "    # core SPO\n",
    "    core = extract_spo(sent)\n",
    "    if core:\n",
    "        all_triples.append(core)\n",
    "\n",
    "    # additional rules\n",
    "    all_triples.extend(extract_appositions(sent))\n",
    "    all_triples.extend(extract_conjunctions(sent))\n",
    "    all_triples.extend(extract_prepositions(sent))\n",
    "    all_triples.extend(extract_numeric_measures(sent))\n",
    "    all_triples.extend(extract_adjectival_modifiers(sent))\n",
    "    all_triples.extend(extract_clausal_complements(sent))\n",
    "    all_triples.extend(extract_acl_relcl(sent))\n",
    "    all_triples.extend(extract_possessives(sent))\n",
    "    all_triples.extend(extract_passive(sent))\n",
    "    all_triples.extend(extract_neg_modality(sent))\n",
    "    all_triples.extend(extract_ner_facts(doc))\n",
    "    \n",
    "    \n",
    "\n",
    "# dedupe & filter\n",
    "unique = list(dict.fromkeys(all_triples))\n",
    "for i, spo in enumerate(unique,1):\n",
    "    print(f\"Triple {i}:\", spo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entity pair extraction**\n",
    "\n",
    "To determine the entity pairs we also make use of the dependency graph. Looking at the first sentence of our example, Leonard Simon Nimoy was born in Boston, we can see that:\n",
    "\n",
    "Entities can be found in noun phrases.\n",
    "The entity tagged as a subj (Leonard Simon Nimoy) is the head of the triple.\n",
    "While the obj (Boston) is the tail and the verb (was born in) in between them is the relation.\n",
    "subj and obj may be composed of several tokens (dep_ == \"compound\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: ['Senator Padmé Luke', 'desert planet']\n",
      "Sentence 2: ['Princess that', 'galaxy']\n",
      "Sentence 3: ['Jedi Master Luke', 'lightsaber']\n",
      "Sentence 4: ['Cloud he', 'lineage']\n"
     ]
    }
   ],
   "source": [
    "def extract_entity_pairs(sent):\n",
    "  head = ''\n",
    "  tail = ''\n",
    "\n",
    "  prefix = ''             # variable for storing compound noun phrases\n",
    "  prev_token_dep = ''     # dependency tag of previous token in the sentence\n",
    "  prev_token_text = ''    # previous token in the sentence\n",
    "\n",
    "  \n",
    "  for token in sent:\n",
    "    # if it's a punctuation mark, do nothing and move on to the next token\n",
    "    if token.dep_ == 'punct':\n",
    "      continue\n",
    "\n",
    "    # Condition #1: subj is the head entity\n",
    "    if \"subj\" in token.dep_:\n",
    "      head = f'{prefix} {token.text}'\n",
    "\n",
    "      # Reset placeholder variables, to be reused by succeeding entities\n",
    "      prefix = ''\n",
    "      prev_token_dep = ''\n",
    "      prev_token_text = ''      \n",
    "\n",
    "    # Condition #2: obj is the tail entity\n",
    "    if token.dep_ in (\"dobj\",\"pobj\",\"iobj\"):\n",
    "      tail = f'{prefix} {token.text}'\n",
    "        \n",
    "    # Condition #3: entities may be composed of several tokens\n",
    "    if token.dep_ == \"compound\":\n",
    "      # if the previous word was also a 'compound' then add the current word to it\n",
    "      if prev_token_dep == \"compound\":\n",
    "        prefix = f'{prev_token_text} {token.text}'\n",
    "      # if not, then this is the first token in the noun phrase\n",
    "      else:\n",
    "        prefix = token.text\n",
    "\n",
    "    # Placeholders for compound cases.      \n",
    "    prev_token_dep = token.dep_\n",
    "    prev_token_text = token.text\n",
    "  #############################################################\n",
    "\n",
    "  return [head.strip(), tail.strip()]\n",
    "\n",
    "for id, sent in enumerate(doc.sents):\n",
    "  print(f'Sentence {id+1}: {extract_entity_pairs(sent)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relation Extraction**\n",
    "\n",
    "To extract the relation, we make use of spaCy's rule-based Matcher class. When we look at our example sentences, we can observe that relations are often tagged as verb phrases. Looking at our dependency graph, we can now define the dependency graph tags as patterns and use the span to identify the corresponding tokens of the relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: raised by\n",
      "Sentence 2: encountered the\n",
      "Sentence 3: learned\n",
      "Sentence 4: culminated in a\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "def extract_relation(sent):\n",
    "\n",
    "  # Rule-based pattern matching class\n",
    "  matcher = Matcher(nlp.vocab)\n",
    "\n",
    "  # define the patterns according to the dependency graph tags \n",
    "  pattern = [{'DEP':'ROOT'},                # verbs are often root\n",
    "            {'DEP':'prep','OP':\"?\"},\n",
    "            {'DEP':'attr','OP':\"?\"},\n",
    "            {'DEP':'det','OP':\"?\"},\n",
    "            {'DEP':'agent','OP':\"?\"}] \n",
    "\n",
    "  matcher.add(\"relation\",[pattern]) \n",
    "\n",
    "  matches = matcher(sent)\n",
    "  k = len(matches) - 1\n",
    "\n",
    "  span = sent[matches[k][1]:matches[k][2]] \n",
    "\n",
    "  return(span.text)\n",
    "\n",
    "for id, sent in enumerate(doc.sents):\n",
    "  print(f'Sentence {id+1}: {extract_relation(sent)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple 1: (Senator Padmé Luke, raised by, desert planet)\n",
      "Triple 2: (Princess that, encountered the, galaxy)\n",
      "Triple 3: (Jedi Master Luke, learned, lightsaber)\n",
      "Triple 4: (Cloud he, culminated in a, lineage)\n"
     ]
    }
   ],
   "source": [
    "for id, sent in enumerate(doc.sents):  \n",
    "  entity_pair = extract_entity_pairs(sent)\n",
    "  print(f'Triple {id+1}: ({entity_pair[0]}, {extract_relation(sent)}, {entity_pair[1]})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
